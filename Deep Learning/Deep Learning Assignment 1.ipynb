{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bee89e5-f8fe-4415-86dd-9c8e5ec3c2ba",
   "metadata": {
    "id": "3bee89e5-f8fe-4415-86dd-9c8e5ec3c2ba"
   },
   "source": [
    "MisBah Sabir \n",
    "Batch IV \n",
    "Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb963333",
   "metadata": {},
   "source": [
    "# <center> REGRESSION using Deep Learning </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18272b14-8e74-46d7-9f95-d4be8a332f32",
   "metadata": {
    "id": "18272b14-8e74-46d7-9f95-d4be8a332f32"
   },
   "source": [
    "### <center> Assignment 1 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84be91-27d4-4beb-bf29-4b25b6893214",
   "metadata": {
    "id": "9f84be91-27d4-4beb-bf29-4b25b6893214"
   },
   "source": [
    "#### Setting up Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d4d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.14.0-cp311-cp311-win_amd64.whl (284.2 MB)\n",
      "     -------------------------------------- 284.2/284.2 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "     -------------------------------------- 938.7/938.7 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.5.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.58.0)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "     ------------------------------------ 440.7/440.7 kB 917.7 kB/s eta 0:00:00\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.13.0\n",
      "    Uninstalling tensorflow-intel-2.13.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "Successfully installed keras-2.14.0 ml-dtypes-0.2.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b5d09b",
   "metadata": {
    "id": "41b5d09b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64354a64-6b60-4e54-b61a-37fa8d9938f0",
   "metadata": {
    "id": "64354a64-6b60-4e54-b61a-37fa8d9938f0"
   },
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c6889",
   "metadata": {
    "id": "a36c6889"
   },
   "outputs": [],
   "source": [
    "concrete_data = pd.read_csv(\"https://cocl.us/concrete_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d044b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "e7d044b2",
    "outputId": "4ea42c79-76d4-4981-8728-8f04996076de"
   },
   "outputs": [],
   "source": [
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6016f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9c6016f",
    "outputId": "c3586527-863c-46cb-de36-4e3d55b3569a"
   },
   "outputs": [],
   "source": [
    "#get data feel using pandas methods of describe/info\n",
    "concrete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vclz8Aj9cgb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "vclz8Aj9cgb7",
    "outputId": "f04c8714-7c1c-4e90-a7e9-7c45379666c5"
   },
   "outputs": [],
   "source": [
    "concrete_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cn03C85eCcem",
   "metadata": {
    "id": "cn03C85eCcem"
   },
   "outputs": [],
   "source": [
    "concrete_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "koVG_oFwM7Tl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "koVG_oFwM7Tl",
    "outputId": "0b8df4bd-5d9f-4895-9512-c30ce2f09145"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 8, figsize=(30, 2))\n",
    "fig.suptitle('Boxplots for outlier detection')\n",
    "sns.boxplot(x=concrete_data['Cement'], ax=axes[0])\n",
    "sns.boxplot(x=concrete_data['Blast Furnace Slag'], ax=axes[1])\n",
    "sns.boxplot(x=concrete_data['Fly Ash'], ax=axes[2])\n",
    "sns.boxplot(x=concrete_data['Water'], ax=axes[3])\n",
    "sns.boxplot(x=concrete_data['Superplasticizer'], ax=axes[4])\n",
    "sns.boxplot(x=concrete_data['Coarse Aggregate'], ax=axes[5])\n",
    "sns.boxplot(x=concrete_data['Fine Aggregate'], ax=axes[6])\n",
    "sns.boxplot(x=concrete_data['Age'], ax=axes[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wzfqCevZObBG",
   "metadata": {
    "id": "wzfqCevZObBG"
   },
   "outputs": [],
   "source": [
    "def outlier_imputer(columns,Inter_QR):\n",
    "    '''\n",
    "    Impute upper-limit values in specified columns based on their interquartile range.\n",
    "\n",
    "    Arguments:\n",
    "        column_list: A list of columns to iterate over\n",
    "        iqr_factor: A number representing x in the formula:\n",
    "                    Q3 + (x * IQR). Used to determine maximum threshold,\n",
    "                    beyond which a point is considered an outlier.\n",
    "\n",
    "    The IQR is computed for each column in column_list and values exceeding\n",
    "    the upper threshold for each column are imputed with the upper threshold value.\n",
    "    '''\n",
    "    for col in columns:\n",
    "        # Reassign minimum to zero\n",
    "        concrete_data.loc[concrete_data[col]<0, col]\n",
    "\n",
    "        # Calculate upper threshold\n",
    "        q1 = concrete_data[col].quantile(0.25)\n",
    "        q3 = concrete_data[col].quantile(0.75)\n",
    "        IQR = q3 - q1\n",
    "        upper_threshold = q3 + (Inter_QR * IQR)\n",
    "        print(col)\n",
    "        print('q3:', q3)\n",
    "        print('upper_threshold:', upper_threshold)\n",
    "\n",
    "\n",
    "        # Reassign values > threshold to threshold\n",
    "        concrete_data.loc[concrete_data[col] > upper_threshold, col] = upper_threshold\n",
    "        print(concrete_data[col].describe().T)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2rLJEd-gPzlN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rLJEd-gPzlN",
    "outputId": "73680891-6e70-4842-d1a9-0799afa26a19"
   },
   "outputs": [],
   "source": [
    "outlier_imputer(['Blast Furnace Slag'],1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqdd6gOdOhUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqdd6gOdOhUE",
    "outputId": "e9a81f6a-df49-443d-d0a8-8e67b92bc33e"
   },
   "outputs": [],
   "source": [
    "outlier_imputer(['Age'],1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bgiDEiokPVgd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgiDEiokPVgd",
    "outputId": "d732b478-445c-497e-86bc-4b7a7c93f29e"
   },
   "outputs": [],
   "source": [
    "outlier_imputer(['Water'],1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-MVqnN0rPeZx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MVqnN0rPeZx",
    "outputId": "85e27742-7f9f-45a8-8245-0d8546d4c9da"
   },
   "outputs": [],
   "source": [
    "outlier_imputer(['Superplasticizer'],1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UdDvWRqCPoTh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdDvWRqCPoTh",
    "outputId": "b8b2208f-09d5-41f3-afa7-65fa45dacd23"
   },
   "outputs": [],
   "source": [
    "outlier_imputer(['Fine Aggregate'],1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cbed6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e2cbed6",
    "outputId": "25e5d4b3-683b-4e8e-86ec-450daac7685d"
   },
   "outputs": [],
   "source": [
    "#check for basics like shape, no of samples\n",
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c8d71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "ba1c8d71",
    "outputId": "de7bff40-61bb-45f3-e20e-3c7fe1f80967"
   },
   "outputs": [],
   "source": [
    "#check if there are null values, and discard null values\n",
    "sns.heatmap(concrete_data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8-ULf5qPdgSa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-ULf5qPdgSa",
    "outputId": "d76f60d0-3aff-4c60-d0a4-7b37afa044ea"
   },
   "outputs": [],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pkmd_BvGgy9N",
   "metadata": {
    "id": "pkmd_BvGgy9N"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f80bef15-b8e4-43f0-b7d8-81cc4649db8b",
   "metadata": {
    "id": "f80bef15-b8e4-43f0-b7d8-81cc4649db8b"
   },
   "source": [
    "#### Splitting data into predictors/features and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6c704",
   "metadata": {
    "id": "86d6c704"
   },
   "outputs": [],
   "source": [
    "X = concrete_data.drop('Strength',axis=1)    # (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23261f67",
   "metadata": {
    "id": "23261f67"
   },
   "outputs": [],
   "source": [
    "y = concrete_data[['Strength']]       # targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076496c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "076496c0",
    "outputId": "38c7e2c1-811f-411b-feeb-22c725c58ba8"
   },
   "outputs": [],
   "source": [
    "# check if any of the features is non-numeric (categorical/ordinal). if found convert these to ohe or other accordingly\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juffffPLnxLP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "juffffPLnxLP",
    "outputId": "a38e521e-3faa-45a9-d4de-2aa6a992cf96"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(X.corr(),cmap='magma',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97394e1",
   "metadata": {
    "id": "c97394e1"
   },
   "source": [
    "### Train_Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3021ac",
   "metadata": {
    "id": "7f3021ac"
   },
   "outputs": [],
   "source": [
    "#Split the data into train / test 90:10 ratio. and keep test data separate for final test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001340e-ae8f-41f8-86a8-ca61d658c934",
   "metadata": {
    "id": "0001340e-ae8f-41f8-86a8-ca61d658c934"
   },
   "source": [
    "### Defining Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081df20",
   "metadata": {
    "id": "9081df20"
   },
   "outputs": [],
   "source": [
    "# define the regression model, use of no. of layers / units is upto you.\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(80, activation='relu'))\n",
    "model.add(layers.Dense(60, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ArYrPzzf7WQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ArYrPzzf7WQ",
    "outputId": "85116891-8a89-4acf-a1f8-67c7bb1dd699"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af4661",
   "metadata": {
    "id": "c5af4661"
   },
   "outputs": [],
   "source": [
    "#add model.compile step\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600bcf3-36b9-43f6-b949-f1a243e402e3",
   "metadata": {
    "id": "b600bcf3-36b9-43f6-b949-f1a243e402e3"
   },
   "source": [
    "### A. Building a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf1899-aa57-4b94-8fbd-0194a9ef367f",
   "metadata": {
    "id": "24bf1899-aa57-4b94-8fbd-0194a9ef367f"
   },
   "source": [
    "#### Model fitting and evaluation (with non_normalized data, epochs=50) -- repeated 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1922b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f1922b6",
    "outputId": "831c1b01-418c-48d1-9eb9-ca732235720d"
   },
   "outputs": [],
   "source": [
    "#use model.fit with non-normalized data.\n",
    "\n",
    "history = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Onw1Gb_ifppX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Onw1Gb_ifppX",
    "outputId": "b9865522-9f09-46d9-faf9-042267d6a0ad"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6846f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cc6846f",
    "outputId": "4f774abe-fdd3-4a08-d888-39ca871b178a"
   },
   "outputs": [],
   "source": [
    "# evaluate mode using test data and print accuracy\n",
    "mae = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e68f76-a7da-4960-8f4b-02f5884ecd71",
   "metadata": {
    "id": "16e68f76-a7da-4960-8f4b-02f5884ecd71"
   },
   "source": [
    "## B. Modeling and Evaluation using 'normalized data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd0efe-1086-4341-b30a-f021e59e115d",
   "metadata": {
    "id": "4fbd0efe-1086-4341-b30a-f021e59e115d"
   },
   "source": [
    "#### Features Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s-24lJwuCDdh",
   "metadata": {
    "id": "s-24lJwuCDdh"
   },
   "outputs": [],
   "source": [
    "# use normalization of the cleaned data (obtained after null checking)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de596b8-81d2-42e5-bc41-b81e72801503",
   "metadata": {
    "id": "9de596b8-81d2-42e5-bc41-b81e72801503"
   },
   "source": [
    "#### train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129bd74",
   "metadata": {
    "id": "9129bd74"
   },
   "outputs": [],
   "source": [
    "#train test split for Normalized Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda6b92-78cf-418b-8b88-7fb7fea0aa04",
   "metadata": {
    "id": "cfda6b92-78cf-418b-8b88-7fb7fea0aa04"
   },
   "source": [
    "### Modeling & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4cffa",
   "metadata": {
    "id": "aff4cffa"
   },
   "outputs": [],
   "source": [
    "#create model with same no. of layers / units and see impact of normalized data on accuracy\n",
    "\n",
    "model_b = keras.Sequential()\n",
    "model_b.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_b.add(layers.Dense(80, activation='relu'))\n",
    "model_b.add(layers.Dense(60, activation='relu'))\n",
    "model_b.add(layers.Dense(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zt_BKK3rBXBn",
   "metadata": {
    "id": "zt_BKK3rBXBn"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_b.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DNFUmYIIMoKP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNFUmYIIMoKP",
    "outputId": "f440f032-20fe-4ff8-fe68-0d548bf2043b"
   },
   "outputs": [],
   "source": [
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NXV23y18kEAV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXV23y18kEAV",
    "outputId": "78956333-27d2-4c79-be55-1c30c9387eab"
   },
   "outputs": [],
   "source": [
    "history_b = model_b.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wBpnTPo0DPuY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBpnTPo0DPuY",
    "outputId": "7b07a6e4-eca2-4d1f-dab6-52bc15e37c6d"
   },
   "outputs": [],
   "source": [
    "y_pred = model_b.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212db21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8212db21",
    "outputId": "acb59cbe-f072-4bb2-8b27-c1dad27d4c71"
   },
   "outputs": [],
   "source": [
    "#evaluate model and print accuracy\n",
    "mae_b = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_b = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_b)\n",
    "print(mse_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47260416-505d-4d8f-b147-0d08ed16e7b8",
   "metadata": {
    "id": "47260416-505d-4d8f-b147-0d08ed16e7b8"
   },
   "source": [
    "### Comparison of loss(MSE) / Accuracy between A & B (non-normalized data vs normalized data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65274611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65274611",
    "outputId": "6ba189f2-e194-4141-ddf2-eec0c53dee6d"
   },
   "outputs": [],
   "source": [
    "# print mse / accuracy\n",
    "\n",
    "print(f'MSE of Non-Normalized Data : {mse} while MSE of Normalized Data is : {mse_b}')\n",
    "print(f'MAE of Non-Normalized Data : {mae} while MAE of Normalized Data is : {mae_b}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec92adb-c139-49c2-86ef-da4ba613e492",
   "metadata": {
    "id": "1ec92adb-c139-49c2-86ef-da4ba613e492"
   },
   "source": [
    "## C. Repeating B with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56205807",
   "metadata": {
    "id": "56205807"
   },
   "outputs": [],
   "source": [
    "#train model at B. with 100 epochs\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, random_state=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PW2Ex0l0FSip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW2Ex0l0FSip",
    "outputId": "e35148eb-b279-4443-b423-e1a1645e2418"
   },
   "outputs": [],
   "source": [
    "#create model with same no. of layers / units and see impact of normalized data on accuracy\n",
    "model_c = keras.Sequential()\n",
    "model_c.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_c.add(layers.Dense(80, activation='relu'))\n",
    "model_c.add(layers.Dense(60, activation='relu'))\n",
    "model_c.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_c.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_c = model_c.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a240d7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a240d7a",
    "outputId": "7d4023fb-3e0c-4b8d-8f35-73f356440d00"
   },
   "outputs": [],
   "source": [
    "#evaluate and store accuracy\n",
    "y_pred = model_c.predict(X_test)\n",
    "\n",
    "mae_c = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_c = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_c)\n",
    "print(mse_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a6086-7239-4231-bbf9-1efedfc10d52",
   "metadata": {
    "id": "010a6086-7239-4231-bbf9-1efedfc10d52"
   },
   "source": [
    "### Comparison of MSE between B & C (increasing epochs=50 to epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cfce7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad3cfce7",
    "outputId": "18aff7c3-fca2-4035-98e6-6b7560119708"
   },
   "outputs": [],
   "source": [
    "# print MSE (error) and Accuracy between B, C\n",
    "\n",
    "# With 50 epochs\n",
    "print(f'with 50 epochs, mse is {mse_b} and mae is {mae_b}')\n",
    "\n",
    "# With 100 epochs\n",
    "print(f'with 100 epochs, mse is {mse_c} and mae is {mae_c}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dff680-ebb6-4d61-8de5-1a96f64d5a47",
   "metadata": {
    "id": "e5dff680-ebb6-4d61-8de5-1a96f64d5a47"
   },
   "source": [
    "## D. Optimized the number of hidden layers using counts 3,4,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455222b-816c-4734-bcc1-da8a4e5e697a",
   "metadata": {
    "id": "3455222b-816c-4734-bcc1-da8a4e5e697a"
   },
   "source": [
    "### Model  fitting and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kvf_J__USVIs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kvf_J__USVIs",
    "outputId": "6b95d7f6-d6cb-46d4-fe40-8ceb12f12027"
   },
   "outputs": [],
   "source": [
    "### with 3 hidden layers\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_d1 = keras.Sequential()\n",
    "model_d1.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_d1.add(layers.Dense(80, activation='relu'))\n",
    "model_d1.add(layers.Dense(60, activation='relu'))\n",
    "model_d1.add(layers.Dense(20, activation='relu'))\n",
    "model_d1.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_d1.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_d1 = model_d1.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y8jj5A7iSbqQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8jj5A7iSbqQ",
    "outputId": "01454e60-4cb4-4468-acc9-060bba4d0644"
   },
   "outputs": [],
   "source": [
    "y_pred = model_d1.predict(X_test)\n",
    "\n",
    "mae_d1 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_d1 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_d1)\n",
    "print(mse_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9c04e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dba9c04e",
    "outputId": "457b20ad-cb60-45c2-93e9-98f9dbd7c591"
   },
   "outputs": [],
   "source": [
    "### with 4 hidden layers\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_d2 = keras.Sequential()\n",
    "model_d2.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_d2.add(layers.Dense(80, activation='relu'))\n",
    "model_d2.add(layers.Dense(60, activation='relu'))\n",
    "model_d2.add(layers.Dense(20, activation='relu'))\n",
    "model_d2.add(layers.Dense(20, activation='relu'))\n",
    "model_d2.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_d2.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_d2 = model_d2.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b07fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec2b07fa",
    "outputId": "1f40a26c-3a78-425f-fa30-665921303fa8"
   },
   "outputs": [],
   "source": [
    "#repeate checking accuracy as above\n",
    "y_pred = model_d2.predict(X_test)\n",
    "\n",
    "mae_d2 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_d2 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_d2)\n",
    "print(mse_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iVZmYi2NU0S4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVZmYi2NU0S4",
    "outputId": "a8ab7e99-5ba3-4f2f-b1c1-9d3d40c77dd8"
   },
   "outputs": [],
   "source": [
    "### with 5 hidden layers\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_d3 = keras.Sequential()\n",
    "model_d3.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_d3.add(layers.Dense(80, activation='relu'))\n",
    "model_d3.add(layers.Dense(60, activation='relu'))\n",
    "model_d3.add(layers.Dense(20, activation='relu'))\n",
    "model_d3.add(layers.Dense(20, activation='relu'))\n",
    "model_d3.add(layers.Dense(20, activation='relu'))\n",
    "model_d3.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_d3.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_d3 = model_d3.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-rFW-I_mVN5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rFW-I_mVN5f",
    "outputId": "c63680f3-5ebe-4aa3-edd0-8ce149d3ffac"
   },
   "outputs": [],
   "source": [
    "#repeate checking accuracy as above\n",
    "y_pred = model_d3.predict(X_test)\n",
    "\n",
    "mae_d3 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_d3 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_d3)\n",
    "print(mse_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a4d01-f7db-404b-a88b-37060b86eadf",
   "metadata": {
    "id": "859a4d01-f7db-404b-a88b-37060b86eadf"
   },
   "source": [
    "## Comparison of MSE between C & D (increasing number of hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866c78b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5866c78b",
    "outputId": "9ab9dd07-f1f6-4d3c-c14f-102fc33451be"
   },
   "outputs": [],
   "source": [
    "#print mse / accuracy\n",
    "\n",
    "print(f'mse is {mse_c} and mae is {mae_c}')\n",
    "\n",
    "print(f'After increasing 1 hidden layer (total 3 layers), mse is {mse_d1} and mae is {mae_d1}')\n",
    "print(f'After increasing 2 hidden layer (total 4 layers), mse is {mse_d2} and mae is {mae_d2}')\n",
    "print(f'After increasing 3 hidden layer (total 5 layers), mse is {mse_d3} and mae is {mae_d3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82893a3d-305f-445a-9ebc-390e2ea6a39c",
   "metadata": {
    "id": "82893a3d-305f-445a-9ebc-390e2ea6a39c"
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715023e",
   "metadata": {
    "id": "5715023e"
   },
   "source": [
    "## E. Increasing the no. of units of hidden layers (16, 32,64,96, ... style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17692d18",
   "metadata": {
    "id": "17692d18"
   },
   "source": [
    "### Model  fitting and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hITTKFiXbaJz",
   "metadata": {
    "id": "hITTKFiXbaJz"
   },
   "source": [
    "***From above summary, it is evident that model with 4 hidden layers is roburst as if we move to 5 hidden layers the loss will be increasing. Hence, we will continue with using 4 hidden layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gAb4kY6dHPMM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAb4kY6dHPMM",
    "outputId": "029351d7-d4a3-4426-f2fd-11164a9072e3"
   },
   "outputs": [],
   "source": [
    "### With neurons as 16\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_e_16 = keras.Sequential()\n",
    "model_e_16.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_e_16.add(layers.Dense(16, activation='relu'))\n",
    "model_e_16.add(layers.Dense(16, activation='relu'))\n",
    "model_e_16.add(layers.Dense(16, activation='relu'))\n",
    "model_e_16.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_e_16.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_e_16 = model_e_16.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sr5F8LRjHPnh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sr5F8LRjHPnh",
    "outputId": "ba649cae-cbe9-4d2d-82ee-3e63622339a8"
   },
   "outputs": [],
   "source": [
    "#repeat checking accuracy as above\n",
    "\n",
    "y_pred = model_e_16.predict(X_test)\n",
    "\n",
    "mae_e_16 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_e_16 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_e_16)\n",
    "print(mse_e_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8cf00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12a8cf00",
    "outputId": "adcf10a5-ddc2-4caf-86c8-8a3730958ba2"
   },
   "outputs": [],
   "source": [
    "### With neurons as 32\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_e_32 = keras.Sequential()\n",
    "model_e_32.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_e_32.add(layers.Dense(32, activation='relu'))\n",
    "model_e_32.add(layers.Dense(32, activation='relu'))\n",
    "model_e_32.add(layers.Dense(32, activation='relu'))\n",
    "model_e_32.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_e_32.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_e_32 = model_e_32.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b2095",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d6b2095",
    "outputId": "bf3d2d43-f30d-4b3a-b448-f1c6763716db"
   },
   "outputs": [],
   "source": [
    "#repeat checking accuracy as above\n",
    "\n",
    "y_pred = model_e_32.predict(X_test)\n",
    "\n",
    "mae_e_32 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_e_32 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_e_32)\n",
    "print(mse_e_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XDSIpXjjGrg4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDSIpXjjGrg4",
    "outputId": "43f4dfa4-05a1-4a3e-80e7-6b90cd441e3f"
   },
   "outputs": [],
   "source": [
    "### With neurons as 64\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_e_64 = keras.Sequential()\n",
    "model_e_64.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_e_64.add(layers.Dense(64, activation='relu'))\n",
    "model_e_64.add(layers.Dense(64, activation='relu'))\n",
    "model_e_64.add(layers.Dense(64, activation='relu'))\n",
    "model_e_64.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_e_64.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_e_64 = model_e_64.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X1vjxf2bGxVh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1vjxf2bGxVh",
    "outputId": "2081021b-4753-4f73-9d36-4cea4ca2025c"
   },
   "outputs": [],
   "source": [
    "#repeat checking accuracy as above\n",
    "\n",
    "y_pred = model_e_64.predict(X_test)\n",
    "\n",
    "mae_e_64 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_e_64 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_e_64)\n",
    "print(mse_e_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kU1ZUhLdGxxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kU1ZUhLdGxxv",
    "outputId": "529a2a60-b747-4497-b49a-e9c70ab190e1"
   },
   "outputs": [],
   "source": [
    "### With neurons as 96\n",
    "\n",
    "# create model as above\n",
    "\n",
    "model_e_96 = keras.Sequential()\n",
    "model_e_96.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model_e_96.add(layers.Dense(96, activation='relu'))\n",
    "model_e_96.add(layers.Dense(96, activation='relu'))\n",
    "model_e_96.add(layers.Dense(96, activation='relu'))\n",
    "model_e_96.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model_e_96.compile(loss='mean_squared_error',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mean_absolute_error'])\n",
    "\n",
    "history_e_96 = model_e_96.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          batch_size=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18gmFIjWGyL2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18gmFIjWGyL2",
    "outputId": "534564a2-4fb9-4a2e-bd2d-3dc83224ab7b"
   },
   "outputs": [],
   "source": [
    "#repeat checking accuracy as above\n",
    "\n",
    "y_pred = model_e_96.predict(X_test)\n",
    "\n",
    "mae_e_96 = round(mean_absolute_error(y_test, y_pred),2)\n",
    "mse_e_96 = round(mean_squared_error(y_test, y_pred),2)\n",
    "\n",
    "print(mae_e_96)\n",
    "print(mse_e_96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c3990",
   "metadata": {
    "id": "782c3990"
   },
   "source": [
    "## Comparison of MSE between C & D (increasing number of hidden layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9Z4otAk5ZCX-",
   "metadata": {
    "id": "9Z4otAk5ZCX-"
   },
   "source": [
    "* model : initial model with 2 hidden layers, 50 epochs using non-normalized data (mae,mse) - history\n",
    "\n",
    "* model_b : model with 2 hidden layers, 50 epochs using normalized data (mae_b,mse_b) - history_b\n",
    "\n",
    "* model_c : model with 2 hidden layers, 100 epochs using normalized data (mae_c,mse_c) - history_c\n",
    "\n",
    "* model_d1 : model with 3 hidden layers, 100 epochs using normalized data (mae_d1,mse_d1) - history_d1\n",
    "\n",
    "* model_d2 : model with 4 hidden layers, 100 epochs using normalized data (mae_d2,mse_d2) - history_d2\n",
    "\n",
    "* model_d3 : model with 5 hidden layers, 100 epochs using normalized data (mae_d3,mse_d3) - history_d3\n",
    "\n",
    "* model_e_16 : model with 4 hidden layers, 100 epochs using normalized data, 16 neurons in each layer (mae_e_16,mse_e_16) - history_e_16\n",
    "\n",
    "* model_e_32 : model with 4 hidden layers, 100 epochs using normalized data, 32 neurons in each layer (mae_e_32,mse_e_32) - history_e_32\n",
    "\n",
    "* model_e_64 : model with 4 hidden layers, 100 epochs using normalized data, 64 neurons in each layer (mae_e_64,mse_e_64) - history_e_64\n",
    "\n",
    "* model_e_96 : model with 4 hidden layers, 100 epochs using normalized data, 96 neurons in each layer (mae_e_96,mse_e_96) - history_e_96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ca049",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "c76ca049",
    "outputId": "ce1ce9a6-2d38-41a0-c093-a17fd4f27ced"
   },
   "outputs": [],
   "source": [
    "#print mse / accuracy\n",
    "\n",
    "results = {\n",
    "    'epochs':[50,50,100,100,100,100,100,100,100,100],\n",
    "    'hidden_layers':[2,2,2,3,4,5,4,4,4,4],\n",
    "    'neurons':['80,60','80,60','80,60','80,60,20','80,60,20,20','80,60,20,20,20','16,16,16,16','32,32,32,32','64,64,64,64','96,96,96,96'],\n",
    "    'mse':[mse,mse_b,mse_c,mse_d1,mse_d2,mse_d3,mse_e_16,mse_e_32,mse_e_64,mse_e_96],\n",
    "    'mae':[mae,mae_b,mae_c,mae_d1,mae_d2,mae_d3,mae_e_16,mae_e_32,mae_e_64,mae_e_96]\n",
    "        }\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrvOC-ClzSrM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "OrvOC-ClzSrM",
    "outputId": "84bcc284-b9b6-4cfb-a219-ce6a45078382"
   },
   "outputs": [],
   "source": [
    "normalization_effect = {\n",
    "    'type':['Normalized','Non-normalized'],\n",
    "    'mse': [mse_b,mse],\n",
    "    'mae': [mae_b,mae]\n",
    "}\n",
    "\n",
    "normalization_effect = pd.DataFrame(normalization_effect)\n",
    "normalization_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tWQvOFaEf5mH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWQvOFaEf5mH",
    "outputId": "c0d17a72-1daa-4f83-c3af-3954acdccdab"
   },
   "outputs": [],
   "source": [
    "min_mae_record = results.loc[results['mae'].idxmin()]\n",
    "min_mae_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bMPuN33iyQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60bMPuN33iyQ",
    "outputId": "dd42ec09-5c17-4bbc-8411-5a811bebd19f"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38882860",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "38882860",
    "outputId": "f5a6c27d-446d-4474-9cf6-62e9039bf54d"
   },
   "outputs": [],
   "source": [
    "#plots of loss / accuracy (as in chapter 4 taught) using history dictionary keys.\n",
    "\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"initial model with 2 hidden layers, 50 epochs using non-normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"initial model with 2 hidden layers, 50 epochs using non-normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uLik-wYfg10J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uLik-wYfg10J",
    "outputId": "a83d2994-ea38-460c-efb3-282eb132328d"
   },
   "outputs": [],
   "source": [
    "history_dict = history_b.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"2 hidden layers, 50 epochs using normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"2 hidden layers, 50 epochs using normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SI8sqskOhRHW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SI8sqskOhRHW",
    "outputId": "7f695c46-2ecd-4662-c075-7206e82fd744"
   },
   "outputs": [],
   "source": [
    "history_dict = history_c.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"2 hidden layers, 100 epochs using normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"2 hidden layers, 100 epochs using normalized data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CLppePDDhQ6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CLppePDDhQ6f",
    "outputId": "971e6a65-8a24-4565-b36b-b2ac9516e1f9"
   },
   "outputs": [],
   "source": [
    "history_dict = history_d1.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"3 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"3 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G8wZqohwnzqD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G8wZqohwnzqD",
    "outputId": "d4fa08dc-fda7-46d7-cfce-6d53e50a9b2f"
   },
   "outputs": [],
   "source": [
    "history_dict = history_d2.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"4 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"4 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qwvx_XK4hQsF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qwvx_XK4hQsF",
    "outputId": "e3ab5b19-975e-4bad-c5c5-be998b5d9214"
   },
   "outputs": [],
   "source": [
    "history_dict = history_d3.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"5 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"5 hidden layers, 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QFpv34ZMoLdC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QFpv34ZMoLdC",
    "outputId": "27fa34f1-3b26-4f2b-8b85-003bf99ec1bd"
   },
   "outputs": [],
   "source": [
    "history_dict = history_e_16.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"4 hidden layers, 16 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"4 hidden layers, 16 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jrRv5jC6oLzK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jrRv5jC6oLzK",
    "outputId": "47d39262-0571-4461-f777-9fb8fecd65d8"
   },
   "outputs": [],
   "source": [
    "history_dict = history_e_32.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"4 hidden layers, 32 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"4 hidden layers, 32 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YVtvZnbcoMuv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YVtvZnbcoMuv",
    "outputId": "8f303ae0-5899-4210-cdaf-7c850d05124e"
   },
   "outputs": [],
   "source": [
    "history_dict = history_e_64.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"4 hidden layers, 64 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"4 hidden layers, 64 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h5HMUooComb-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h5HMUooComb-",
    "outputId": "75a6ef37-db1a-42da-b410-b1643266de0c"
   },
   "outputs": [],
   "source": [
    "history_dict = history_e_96.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",color='red')\n",
    "plt.title(\"4 hidden layers, 96 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history_dict[\"mean_absolute_error\"]\n",
    "val_acc = history_dict[\"val_mean_absolute_error\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\",color='magenta')\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"4 hidden layers, 96 neurons in each layer\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy-Mean Absolute Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n02HxewTMKpC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "n02HxewTMKpC",
    "outputId": "c2d2714d-7468-4744-d51a-aeea0db5628b"
   },
   "outputs": [],
   "source": [
    "# write what you saw when using non-normalized vs normalized data, increased epochs, layers and units.|\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sVd6Uo614fX0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "sVd6Uo614fX0",
    "outputId": "bc1312cb-98dd-45f2-80d5-24429a2d4fc3"
   },
   "outputs": [],
   "source": [
    "normalization_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DV6wg1ICsWHS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "DV6wg1ICsWHS",
    "outputId": "a374c71f-4f45-4d6d-d0f5-2e4e5dd6cbd1"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TIJgzQLPxhNm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "id": "TIJgzQLPxhNm",
    "outputId": "e396df1b-be8d-4d71-890e-e592e2e2638a"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(25, 3))\n",
    "fig.suptitle('Normalization of features Effect on Loss and Accuracy')\n",
    "sns.barplot(data=normalization_effect, x='mae', y='type', ax=axes[0])\n",
    "sns.barplot(data=normalization_effect, x='mse', y='type', ax=axes[1])\n",
    "axes[0].set_ylabel('')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 3))\n",
    "fig.suptitle('Epochs Effect on Loss and Accuracy')\n",
    "sns.lineplot(x=\"epochs\", y=\"mae\", data=results, label=\"MAE\", marker=\"o\", ax=axes[0])\n",
    "sns.lineplot(x=\"epochs\", y=\"mse\", data=results, label=\"MSE\", marker=\"o\", ax=axes[1], color='green')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 3))\n",
    "fig.suptitle('Hidden Layers Effect on Loss and Accuracy')\n",
    "sns.lineplot(x=\"hidden_layers\", y=\"mae\", data=results, label=\"MAE\", marker=\"o\", ax=axes[0])\n",
    "sns.lineplot(x=\"hidden_layers\", y=\"mse\", data=results, label=\"MSE\", marker=\"o\", ax=axes[1], color='green')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 3))\n",
    "results['neurons_list'] = results['neurons'].apply(lambda x: [int(neuron) for neuron in x.split(',')])\n",
    "results['neurons_average'] = results['neurons_list'].apply(lambda x: sum(x) / len(x))\n",
    "fig.suptitle('No. of Neurons Effect on Loss and Accuracy')\n",
    "sns.lineplot(x=\"neurons_average\", y=\"mae\", data=results[7:], label=\"MAE\", marker=\"o\", ax=axes[0])\n",
    "sns.lineplot(x=\"neurons_average\", y=\"mse\", data=results[7:], label=\"MSE\", marker=\"o\", ax=axes[1], color='green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cabc9-1abe-440a-b493-0f4e45daa1ad",
   "metadata": {
    "id": "789cabc9-1abe-440a-b493-0f4e45daa1ad"
   },
   "source": [
    "### It is therefore evident that;\n",
    "#### -normalization the data reduces MSE and MAE\n",
    "#### -increasing the number of epochs reduces MSE and MAE\n",
    "#### -increasing the number of layers reduces MSE and MAE\n",
    "#### -and increasing the number of units also reduces MSE and MAE but to a certain level after which it starts increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4tzf_lN-uoSK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "4tzf_lN-uoSK",
    "outputId": "53a293e1-1bb9-45a9-f6de-cc00dc99e6a0"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dba235",
   "metadata": {
    "id": "55dba235"
   },
   "source": [
    "1. You can use model name as modelA, modelB etc. for sections A,B,....to avoid error.\n",
    "2. MSE is mean squared error normally used in regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eNAdMUb7_g4B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNAdMUb7_g4B",
    "outputId": "f2ba62d0-9c3e-4c97-d8f1-e980f01b9e0a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xq9IB5x_q3O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xq9IB5x_q3O",
    "outputId": "4404273f-6447-4849-ebaf-f05e888925b8"
   },
   "outputs": [],
   "source": [
    "!pip install nbconvert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cv7O8ycrAIaL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cv7O8ycrAIaL",
    "outputId": "05a68f4f-1018-4882-c216-693e3e929df6"
   },
   "outputs": [],
   "source": [
    "!apt-get install texlive-xetex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OZGXd2gT_rhG",
   "metadata": {
    "id": "OZGXd2gT_rhG"
   },
   "outputs": [],
   "source": [
    "from nbconvert import PDFExporter\n",
    "import nbformat\n",
    "\n",
    "# Open the notebook file\n",
    "notebook_file = '/content/drive/MyDrive/Assignment - 1 Regression - Week 4.ipynb'\n",
    "with open(notebook_file, 'r', encoding='utf-8') as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Initialize PDF export\n",
    "pdf_exporter = PDFExporter()\n",
    "pdf_data, resources = pdf_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Save the PDF\n",
    "pdf_file_path = '/content/drive/MyDrive/Assignment - 1 Regression - Week 4 (Ali Affan Yaqoob).pdf'\n",
    "with open(pdf_file_path, 'wb') as f:\n",
    "    f.write(pdf_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2JmvcT5R-K0y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JmvcT5R-K0y",
    "outputId": "196cb03d-8ca2-4264-c176-26238590c956"
   },
   "outputs": [],
   "source": [
    "predict = model_e_64.predict(X_test)\n",
    "\n",
    "predicted = predict[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769cf925",
   "metadata": {
    "id": "769cf925"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceUR44SUCij1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ceUR44SUCij1",
    "outputId": "8da693d4-c08f-408a-e9e2-ad6ce651316b"
   },
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujRJhWvMBJ5M",
   "metadata": {
    "id": "ujRJhWvMBJ5M"
   },
   "outputs": [],
   "source": [
    "actual = y_test.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M8lIKyhqBP9Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "M8lIKyhqBP9Y",
    "outputId": "61757668-4adc-49d3-a2bb-da8f61227ef4"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=actual['Strength'], y=predicted.ravel(),color='blue')\n",
    "plt.ylabel('Predicted Strength')\n",
    "plt.xlabel('Actual Strength')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91pfWFDoC4j-",
   "metadata": {
    "id": "91pfWFDoC4j-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
